{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map continent data with yield.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_data = pd.read_csv('processed_data/processed_yield.csv')\n",
    "\n",
    "continent_data = pd.read_csv('processed_data/countries_by_continent_sorted.csv')\n",
    "\n",
    "combined_yield = pd.merge(yield_data, continent_data, how='left', left_on='Area', right_on='Country')\n",
    "\n",
    "combined_yield = combined_yield.drop(columns=['Country']).rename(columns={'Continent': 'Country_Continent'})\n",
    "\n",
    "combined_yield.to_csv('processed_data/yield_continent.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map pesticides data with the updated yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_data = pd.read_csv('processed_data/yield_continent.csv')\n",
    "\n",
    "pesticides_data = pd.read_csv('processed_data/processed_pesticides.csv')\n",
    "\n",
    "combined_yield = pd.merge(yield_data, pesticides_data, how='left', on=['Area', 'Year'])\n",
    "\n",
    "combined_yield.to_csv('processed_data/yield_continent_pesticides.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map rainfall data with the updated yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_data = pd.read_csv('processed_data/yield_continent_pesticides.csv')\n",
    " \n",
    "rainfall_data = pd.read_csv('processed_data/processed_rainfall.csv')\n",
    " \n",
    "combined_yield = pd.merge(yield_data, rainfall_data, how='left', on=['Area', 'Year'])\n",
    " \n",
    "combined_yield.to_csv('processed_data/yield_continent_pesticides_rainfall.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map temperature data with the updated yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_data = pd.read_csv('processed_data/yield_continent_pesticides_rainfall.csv')\n",
    " \n",
    "temperature_data = pd.read_csv('processed_data/processed_temp.csv')\n",
    "\n",
    "combined_yield = pd.merge(yield_data, temperature_data, how='left', left_on=['Area', 'Year'], right_on=['country', 'year'])\n",
    "\n",
    "combined_yield = combined_yield.drop(columns=['country', 'year'])\n",
    "\n",
    "combined_yield.to_csv('processed_data/combined_raw_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'processed_data/combined_raw_data.csv'\n",
    " \n",
    "columns_to_delete = ['Domain Code', 'Domain_x', 'Area Code', 'Element_x', 'Element Code', 'Year Code', 'Domain_y', 'Element_y', ]\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df = df.drop(columns=columns_to_delete, errors='ignore')\n",
    "\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete rows that do not have values for the following columns 'Item_y', 'Unit_y', 'Value_y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted: 4180 records\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = 'processed_data/combined_raw_data.csv'\n",
    "\n",
    "columns_to_delete = ['Item_y', 'Unit_y', 'Value_y', 'Country_Continent']\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "records_before = len(df)\n",
    "\n",
    "df = df.dropna(subset=columns_to_delete, how='any')\n",
    "\n",
    "records_after = len(df)\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    " \n",
    "n = records_before - records_after\n",
    " \n",
    "print(f\"deleted: {n} records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count the number of records per continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before renaming the column\n",
    "# file_path = 'processed_data/combined_raw_data.csv'\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# result = df.groupby(['Country_Continent', 'Item_x']).size().reset_index(name='Count')\n",
    "\n",
    "# print(result)\n",
    "\n",
    "# file_path = 'processed_data/combined_raw_data.csv'\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# result = df.groupby(['Continent', 'Crop']).size().reset_index(name='Count')\n",
    "\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the rows that do have only records for year range 1992-2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = 'processed_data/combined_raw_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# column_to_check = 'avg_temp'\n",
    "column_to_check = 'average_rain_fall_mm_per_year'\n",
    "\n",
    "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
    "\n",
    "rows_to_delete = df[(df['Year'] >= 1992) & (df['Year'] <= 2013) & (df[column_to_check].isnull())].index\n",
    "\n",
    "df.drop(rows_to_delete, inplace=True)\n",
    "\n",
    "df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill in the values where there are single missing values for average_rain_fall_mm_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_empty_with_mean(csv_file_path): \n",
    "    df = pd.read_csv(csv_file_path)\n",
    " \n",
    "    for i in range(1, len(df) - 1):\n",
    "        if pd.isna(df.at[i, 'average_rain_fall_mm_per_year']): \n",
    "            mean_value = (df.at[i-1, 'average_rain_fall_mm_per_year'] + df.at[i+1, 'average_rain_fall_mm_per_year']) / 2\n",
    " \n",
    "            df.at[i, 'average_rain_fall_mm_per_year'] = mean_value\n",
    " \n",
    "    df.to_csv(csv_file_path, index=False)\n",
    " \n",
    "fill_empty_with_mean('processed_data/combined_raw_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "managing final column operations(delete, rename, reordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'processed_data/combined_raw_data.csv'\n",
    "\n",
    "rename_columns = {\n",
    "    # 'old_column_name': 'new_column_name',\n",
    "    'Area': 'Country', \n",
    "    'Item_x': \"Crop\",\n",
    "    'Value_x': 'Quantity(hg/ha)',\n",
    "    'Country_Continent': 'Continent',\n",
    "    'Value_y': 'Pesticide use(toai)',\n",
    "    'average_rain_fall_mm_per_year': 'Rainfall(mm)',\n",
    "    'avg_temp': 'Temperature(C)', \n",
    "}\n",
    " \n",
    "reorder_columns = ['Continent', 'Country', 'Year', 'Temperature(C)', 'Rainfall(mm)', 'Pesticide use(toai)', 'Crop', 'Quantity(hg/ha)']\n",
    " \n",
    "# delete_columns = ['column_to_delete1', 'column_to_delete2', 'column_to_delete3']\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.rename(columns=rename_columns, inplace=True)\n",
    " \n",
    "df = df[reorder_columns]\n",
    " \n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "import os \n",
    "os.remove('processed_data/yield_continent_pesticides.csv')\n",
    "os.remove('processed_data/yield_continent.csv')\n",
    "os.remove('processed_data/yield_continent_pesticides_rainfall.csv')\n",
    "os.remove('processed_data/processed_temp.csv') \n",
    "os.remove('processed_data/processed_pesticides.csv')\n",
    "os.remove('processed_data/processed_rainfall.csv')\n",
    "os.remove('processed_data/processed_yield.csv') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandu/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Continent  Year  Temperature(C)  Rainfall(mm)  Country_Algeria  \\\n",
      "0    Europe  1992           16.06        1485.0              0.0   \n",
      "1    Europe  1993           16.05        1485.0              0.0   \n",
      "2    Europe  1994           16.96        1485.0              0.0   \n",
      "3    Europe  1995           15.67        1485.0              0.0   \n",
      "4    Europe  1996           15.64        1485.0              0.0   \n",
      "\n",
      "   Country_Angola  Country_Antigua and Barbuda  Country_Argentina  \\\n",
      "0             0.0                          0.0                0.0   \n",
      "1             0.0                          0.0                0.0   \n",
      "2             0.0                          0.0                0.0   \n",
      "3             0.0                          0.0                0.0   \n",
      "4             0.0                          0.0                0.0   \n",
      "\n",
      "   Country_Armenia  Country_Australia  ...  Pesticide use(toai)_214725.0  \\\n",
      "0              0.0                0.0  ...                           0.0   \n",
      "1              0.0                0.0  ...                           0.0   \n",
      "2              0.0                0.0  ...                           0.0   \n",
      "3              0.0                0.0  ...                           0.0   \n",
      "4              0.0                0.0  ...                           0.0   \n",
      "\n",
      "   Pesticide use(toai)_232232.0  Pesticide use(toai)_238716.0  \\\n",
      "0                           0.0                           0.0   \n",
      "1                           0.0                           0.0   \n",
      "2                           0.0                           0.0   \n",
      "3                           0.0                           0.0   \n",
      "4                           0.0                           0.0   \n",
      "\n",
      "   Pesticide use(toai)_304031.0  Pesticide use(toai)_312637.0  \\\n",
      "0                           0.0                           0.0   \n",
      "1                           0.0                           0.0   \n",
      "2                           0.0                           0.0   \n",
      "3                           0.0                           0.0   \n",
      "4                           0.0                           0.0   \n",
      "\n",
      "   Pesticide use(toai)_335742.0  Pesticide use(toai)_342580.0  \\\n",
      "0                           0.0                           0.0   \n",
      "1                           0.0                           0.0   \n",
      "2                           0.0                           0.0   \n",
      "3                           0.0                           0.0   \n",
      "4                           0.0                           0.0   \n",
      "\n",
      "   Pesticide use(toai)_345026.0  Pesticide use(toai)_346583.0  \\\n",
      "0                           0.0                           0.0   \n",
      "1                           0.0                           0.0   \n",
      "2                           0.0                           0.0   \n",
      "3                           0.0                           0.0   \n",
      "4                           0.0                           0.0   \n",
      "\n",
      "   Pesticide use(toai)_367778.0  \n",
      "0                           0.0  \n",
      "1                           0.0  \n",
      "2                           0.0  \n",
      "3                           0.0  \n",
      "4                           0.0  \n",
      "\n",
      "[5 rows x 2090 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14574 entries, 0 to 14573\n",
      "Columns: 2088 entries, Temperature(C) to Pesticide use(toai)_367778.0\n",
      "dtypes: float64(2088)\n",
      "memory usage: 232.2 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load your data from the CSV file\n",
    "file_path = 'processed_data/combined_raw_data.csv'\n",
    "yield_df = pd.read_csv(file_path)\n",
    "\n",
    "# Select columns to one-hot encode\n",
    "columns_to_encode = ['Country', 'Crop', 'Pesticide use(toai)']\n",
    "\n",
    "# Perform one-hot encoding\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoded_features = pd.DataFrame(encoder.fit_transform(yield_df[columns_to_encode]),\n",
    "                                columns=encoder.get_feature_names_out(columns_to_encode))\n",
    "\n",
    "# Concatenate the encoded features with the original dataframe\n",
    "yield_df_encoded = pd.concat([yield_df, encoded_features], axis=1)\n",
    "\n",
    "# Drop the original columns that were encoded\n",
    "yield_df_encoded.drop(columns=columns_to_encode, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = yield_df_encoded.loc[:, yield_df_encoded.columns != 'Quantity(hg/ha)']\n",
    "label = yield_df['Quantity(hg/ha)']\n",
    "\n",
    "# Display the head of the features dataframe\n",
    "print(features.head()) \n",
    "features = features.drop(['Year'], axis=1)\n",
    "features = features.drop(['Continent'], axis=1)\n",
    "features.to_csv(\"urmom.csv\", index=False)\n",
    "features.info()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
